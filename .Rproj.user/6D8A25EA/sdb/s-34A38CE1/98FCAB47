{
    "collab_server" : "",
    "contents" : "---\ntitle: \"Regressione polinomiale\"\ndate: \"8 Maggio 2018\"\noutput:\n  pdf_document:\n    fig_width: 5\n    number_sections: yes\n    template: /Users/andrea/Documents/_DBXAndrea/Dropbox/MyTemplates/Latex/mmLatexSimpleIta.tex \n    toc: yes\n  word_document: default\n---\n\n#Introduzione\n\nIn alcune situazioni un modello lineare è più che sufficiente per descrivere un fenomeno biologico, soprattutto quando il nostro interesse risiede in un intervallo abbastanza ristretto della variabile indipendente (approssimazione locale). Ad esempio, se stiamo studiando la relazione tra la densità delle piante infestanti e la produttività di una coltura, è ragionevole attendersi che essa segua un andamento iperbolico decrescente, con un certo asintoto inferiore (figura sottostante). Tuttavia, se vogliamo studiare la soglia economica d'intervento, che in genere si trova a valori piuttosto bassi di densità, il nostro interesse risiede solo nella prima parte della curva, che potremmo quindi approssimare con una retta:\n\n\\[\nP = a D + b + \\epsilon\n\\]\n\ndove la produzione P è funzione lineare della densità D, con due parametri a (pendenza) e b (intercetta). Le produzioni effettivamente osservate saranno tuttavia influenzate anche dalla variabilità casuale $\\epsilon$ (errore sperimentale), normalmente distributa con media 0 e varianza pari a $\\sigma^2$.\n\n```{r setup, cache = F, echo = F}\n#Put at the beginning\nknitr::knit_hooks$set(document = function(x){ \n  gsub(\"```\\n*```r*\\n*\", \"\", x) \n})\n```\n\n\n```{r}\nhip <- function(x, i, a, P) P * (1 - i*x/(1+i*x/a))\ncurve(hip(x,0.2, 0.8, 30), from=0, to=10, \n      xlab=\"Densità malerbe\", ylab=\"Produzione\")\ncurve(30-3.7*x, add=T, from=0, to=3, col=\"red\")\n```\n\nPuò capitare però che l'esperimento metta in luce un'evidente curvatura, che non può essere descritta con una retta, ma richiede una funzione curvilinea.\n\n#Il caso studio\n\nPer parametrizzare la relazione lineare densità-produzione esposta in precedenza, è stato organizzato un esperimento a blocchi randomizzati, dove sono stati inclusi sette diversi livelli di infestazione di *Sinapis arvensis* ed è stata rilevata la produzione di acheni del girasole. I risultati sono:\n\n```{r}\nlibrary(aomisc)\ndata(sinapis)\nsinapis\n```\n\nI dati osservati mostrano una lieve curvatura della risposta. Si tratta di una curvatura rilevante, tanto da richiedere un fitting curvilineo?\n\n```{r echo=F, results=\"hide\"}\nmedie <- plyr::ddply(sinapis, c(\"density\"), \n      function(df) c(Mean=mean(df$yield)))\n\nplot(Mean ~ density, data=medie, ylim=c(25,39), \n     xlab=\"Densità (piante per mq)\", \n     ylab=\"Produzione girasole (q/ha)\", type=\"b\", \n     pch=21, bg=\"black\")\n\npoints(yield ~ density, data=sinapis)\n```\n\n\nIniziamo questo studio verificando il rispetto delle assunzioni di base ed eseguendo l'ANOVA, che pormette di calcolare il SEM e il coefficiente di variabilità, da utilizzare come 'descrittori' della bontà della prova e dell'incertezza dei risultati. In questo caso il test d F e i confronti multipli sono abbastanza irrilevanti, rispetto agli obiettivi dell'esperimento.\n\n\n```{r}\nmod <- lm(yield ~ factor(density), data=sinapis)\nanova(mod)\n```\n\n# Stima dei parametri\n\nDato che il modello è lineare, la stima dei parametri può essere eseguita con il metodo dei minimi quadrati\n\nDando per scontato il rispetto degli assunti di base (che comunque andrebbe verificato opportunamente), possiamo procedere alla parametrizzazione del modello, utilizzando i dati ottenuti nel'esperimento.\n\n```{r}\nmodReg <- lm(yield ~ density, data=sinapis)\nsummary(modReg)\n```\n\n\n# Bontà della regressione\n\nDopo la stima dei parametri, è necessario valutare la bontà del modello. In *primis*, dato che il metodo dei minimi quadrati lavora in base alle stesse assunzioni dell'ANOVA, gli strumenti diagnostici più immediati sono gli stessi già consigliati in precedenza e fondamentalmente basati sull'analisi dei residui. I residui si calcolano sottraendo dai valori osservati, i valori attesi, secondo il modello di regressione. Ad esempio, per il primo dato la produzione osservata è stata 36.63, mentre la produzione attesa avrebbe dovuto essere 35.67 - 0.2055 $\\times$ 0 = 35.67. Il residuo è quindi 0.957.\n\nPossiamo valutare il grafico di dispersione dei dati osservati e stimati vs la variabile indipendente e il grafico dei residui vs. gli attesi. Nel caso in studio i grafici sono riportati più sotto.\n\n```{r}\npar(mfrow=c(1,2))\nmedie <- as.data.frame(emmeans::emmeans(mod, ~density, \n                                        data=sinapis))\nplot(emmean ~ density, data=medie, ylim=c(25,39), \n     xlab=\"Densità (piante per mq)\", \n     ylab=\"Produzione girasole (q/ha)\")\nabline(modReg)\nplot(modReg$residuals ~ modReg$fitted, xlab=\"Attesi\", \n     ylab=\"Residui\", ylim=c(-2,2))\nabline(h=0, lty=2)\n```\n\nIl grafico di sinistra mostra che i dati osservati hanno una lieve tendenza curvilinea (coerente con le aspettative sul fenomeno competitivo) e, in particolare, sia i dati a densità 0, sia a quelli a densità 54 sono sopra la retta di regressione.\n\nGli errori standard dei parametri sono inferiori alla metà del valore stimato e, di conseguenza, concludiamo che le stime sono buone.\n\nIl test di lack of fit, porta ai seguenti risultati e non è significativo, anche se è vicino alla soglia di significanza:\n\n```{r}\nanova(modReg, mod)\n```\n\n\n# Regressione curvilinea\n\nSembra che la descrizione lineare del fenomeno competitivo sia sufficientemente buona, anche se permangono dei dubbi all'analisi dei residui e, inoltre, sappiamo che in natura il fenomeno non dovrebbe essere lineare, ma curvilineo.\n\nInsomma, c'è da chiedersi se l'uso di una regressione lineare per un fenomeno 'curvilineo' in natura sia effettivamente sufficiente. Per questo motivo, utilizziamo un modello curvilineo, sotto forma di una polinomiale di secondo grado (parabola). I risultati sono i seguenti:\n\n```{r}\nmodReg2 <- lm(yield ~ density + I(density^2), data=sinapis)\nsummary(modReg2)\n```\n\nIl test di lack of fit è non significativo:\n\n```{r}\nanova(modReg2, mod)\n```\n\nIl residuo del modello polinomiale è minore di quello lineare: abbiamo un parametro aggiuntivo che consente di migliorare l'adattamento, ma fa diventare il modello più complesso. Ricordiamo che per il principio del rasoio di Occam, dobbiamo scegliere sempre il modello più semplice, a parità di adattamento.\n\nCi chiediamo: ma se passiamo dal modello più complesso (polinomiale) a quello più semplice (lineare) abbiamo un significativo peggioramento della bontà d'adattamento?\n\nIl residuo del modello polinomiale è 85.58 con 25 gradi di libertà. Il residuo del modello lineare è pari a 101.55, con 26 gradi di libertà. La differenza tra i due modelli è 15.965, con 26 - 25 = 1 grado di libertà. Il test di F per l' 'extra-devianza' è dato dal rapporto delle varianze 15.965/3.423:\n\n$$F = \\frac{\\frac{RSS_f  - RSS_s}{DF_f  - DF_s }}{\\frac{RSS_f}{DF_f}} = \\frac{\\frac{101.55 - 85.58}{26 - 25}}{\\frac{85.58}{25}} = 4.66$$\n\ned è significativo:\n\n```{r}\nanova(modReg, modReg2)\n```\n\nDobbiamo quindi concludere che il modello migliore è quello polinomiale, dato che il modello lineare, anche se più semplice, è significativamente peggiore in termini di adattamento.\n\n# Per approfondimenti\n\nCAMUSSI Alessandro , MOELLER Frank , OTTAVIANO Ercole , SARI GORLA Mirella (1995). Metodi Statistici per la sperimentazione biologica. Zanichelli Editore, 496 pp.\n\n",
    "created" : 1528893470469.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "432948620",
    "id" : "98FCAB47",
    "lastKnownWriteTime" : 1528896285,
    "last_content_update" : 1528896285680,
    "path" : "~/Documents/_DBXAndrea/Dropbox/_Lavoro/__Notes/__Stats/40 - LinearModels/_LinearRegressionModels/_ParametrizzazioneModelliLinear/SimplePolynomialRegression/PolynomialRegression.Rmd",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}