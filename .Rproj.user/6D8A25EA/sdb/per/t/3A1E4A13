{
    "collab_server" : "",
    "contents" : "---\ntitle: \"Linear regression analysis\"\nauthor: \"Andrea Onofri\"\noutput: pdf_document\n---\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = FALSE)\ndevtools::install_github(\"OnofriAndreaPG/aomisc\")\n```\n\n#Introduzione\n\nNella sperimentazione agronomica e biologica in genere è normale organizzare prove sperimentali replicate, anche per studiare l'effetto di una fattore quantitativo su una variabile dipendente, anch'essa quantitativa.\n\nIn questa situazione, l'impiego di metodiche di confronto multiplo, se non del tutto errato, è comunque da considerare 'improprio'. Infatti, l'inclusione di alcuni particolari livelli della variabile indipendente è frutto solo delle esigenze organizzative, senza alcune interesse particolare per lo sperimentatore, che è invece interessato a capire come cresce/decresce/varia la Y (variabile dipendente) in funzione della X (variabile indipendente). In sostanza lo sperimentatore è interessato a definire una funzione di risposta e non a confrontare tra loro la risposta a due particolari livelli di X.\n\nImmaginiamo una prova sperimentale organizzata per valutare l'effetto della concimazione azotata sulla produzione del frumento, i cui risultati sono riportati sono visualizzati di seguito.\n\n```{r}\nlibrary(aomisc)\ndata(NWheat)\nNWheat\n```\n\nTrattandosi di una prova replicata, l'analisi inizia, come al solito, con l'ANOVA, che porta al seguente risultato:\n\n```{r}\nmodel <- lm(Yield ~ factor(Dose), data=NWheat)\nanova(model)\n```\n\nOsserviamo che l'effetto del trattamento è significativo e il SEM è pari a 1.15. Prima di proseguire, verifichiamo che non ci sono problemi relativi alle assunzioni parametriche di base e che, quindi, la trasformazione dei dati non è necessaria. Il grafico dei residui, riportato di seguito, mostra che non vi sono patologie rilevanti.\n\n```{r}\npar(mfrow=c(2,2))\nplot(model)\n```\n\nPer maggior sicurezza, possiamo anche eseguire test statistici di verifica dell'omogeneità delle varianze (test di Bartlett e test di Levene) o della normalità dei residui (test di Shapiro-Wilks)\n\n```{r}\nbartlett.test(Yield ~ factor(Dose), data=NWheat)\ncar::leveneTest(Yield ~ factor(Dose), data=NWheat)\nshapiro.test(residuals(model))\n```\n\nInsomma, non paiono sussistere problemi con le assunzioni di base per i modelli lineari.\n\nDa questo momento in avanti, l'analisi non prosegue con un test di confronto multiplo (infatti quale senso avrebbe confrontare tra loro le risposte a N0, N60, N120 e così via?), ma con una analisi di regressione. Valutando graficamente l'andamento dei dati e considerando la biologia del fenomeno, immaginiamo che la relazione tra la dose di concime e la produzione, possa essere approssimata con una retta:\n\n$$Y_i = b_0 + b_1 X_i + \\varepsilon_i$$\n\ndove la produzione Y è funzione lineare della dose X, con due parametri $b_1$ (pendenza) e $b_0$ (intercetta). Le produzioni effettivamente osservate saranno tuttavia influenzate anche dalla variabilità casuale $\\varepsilon$ (errore sperimentale), normalmente distributa con media 0 e deviazione standard pari a $\\sigma$.\n\n#Stima dei parametri\n\nDobbiamo a questo punto individuare i parametri $b_0$ e $b_1$ in modo tale che la retta ottenuta sia la più vicina ai dati, cioè in modo da minimizzare gli scostamenti tra i valori di produzione osservati e quelli stimati dal modello (soluzione dei minimi quadrati). La funzione dei minimi quadrati è:\n\n\n$$\\begin{array}{l}\nQ = \\sum\\limits_{i = }^N {\\left( {{Y_i} - \\hat Y} \\right)^2 = \\sum\\limits_{i = }^N {{{\\left( {{Y_i} - {b_0} - {b_1}{X_i}} \\right)}^2}}  = } \\\\\n = \\sum\\limits_{i = }^N {\\left( {Y_i^2 + b_0^2 + b_1^2X_i^2 - 2{Y_i}{b_0} - 2{Y_i}{b_1}{X_i} + 2{b_0}{b_1}{X_i}} \\right)}  = \\\\\n = \\sum\\limits_{i = }^N {Y_i^2 + Nb_0^2 + b_1^2\\sum\\limits_{i = }^N {X_i^2 - 2{b_0}\\sum\\limits_{i = }^N {Y_i^2 - 2{b_1}\\sum\\limits_{i = }^N {{X_i}{Y_i} + } } } } 2{b_0}{b_1}\\sum\\limits_{i = }^N {{X_i}} \n\\end{array}$$\n\n\nCalcolando le derivate parziali rispetto a $b_0$ e $b_1$ che, al momento, sono le nostre incognite, ed eguagliandole a 0 si ottengono le seguenti formule risolutive:\n\n\n$${b_1} = \\frac{{\\sum\\limits_{i = 1}^N {\\left[ {\\left( {{X_i} - {\\mu _X}} \\right)\\left( {{Y_i} - {\\mu _Y}} \\right)} \\right]} }}{{\\sum\\limits_{i = 1}^N {{{\\left( {{X_i} - {\\mu _X}} \\right)}^2}} }}$$\n\ne\n\n$${b_0} = {\\mu _Y} - {b_1}{\\mu _X}$$\n\nInvece che svolgere i calcoli a mano, possiamo utilizzare EXCEL, che propone due diverse possibilità:\n\n1. disegnare il grafico a dispersione, click destro sui 'punti', utilizzare la funzione 'inserisci linea di tendenza', spuntando le opzioni relative a 'visualizza la funzione sul grafico' e visualizza il valore di R quadrato sul grafico'.\n2. utilizzare la funzione REGR.LIN()\n\nLa prima opzione è più semplice, ma fornisce solo le stime dei parametri, senza errori standard, che sono invece fondamentali per valutare l'incertezza della stima (analogamente al SEM nel caso delle medie).\n\n![Uso della linea di tendenza con EXCEL](Trendline.png){width=90%}\n\n\nDato che il modello è lineare, la stima dei parametri può essere eseguita con la funzione REGR.LIN(y\\_nota, x\\_nota, int, stat), che ha quattro argomenti: il primo rappresenta l'intervallo che contiene la Y osservata, il secondo rappresenta l'intervallo che contiene la X osservata, il terzo argomento (int) rappresenta il valore logico VERO/FALSO e specifica se vogliamo un'intercetta esplicita o vogliamo invece una retta per l'origine (nel nostro caso useremo VERO), mentre il quarto argomento rappresenta un valore logico VERO/FALSO, che specifica se vogliamo le statistiche addizionali (nel nostro caso inseriremo VERO). REGR.LIN è una funzione di matrice, che deve essere immessa in questo modo:\n\n1. selezionare un intervallo composto da 5 righe e tante colonne quanti sono i parametri da stimare (in questo caso due)\n2. immettere la funzione nella cella attiva, mantenendo l'intervallo selezionato\n3. Consolidare la formula premendo contemporaneamente CTRL+SHIFT+INVIO.\t \n\nIl risultato propone i seguenti valori:\n\n![Risultati della funzione REGR.LIN() in EXCEL](regrLin.png){width=90%}\n\nNella prima riga vi sono le stime dei minimi quadrati (rispettivamente $b_1$ e $b_0$), nella seconda riga gli errori standard, nella terza riga abbiamo il coefficiente di determinazione ($R^2$ a sinistra) e l'errore standard di un valore stimato y (a destra), nella quarta riga abbiamo il valore di F per la regressione, per testare l'ipotesi che la relazione tra x e y è solo casuale (a sinistra) e il numero dei gradi di libertà della regressione (a destra; è pari al numero dei dati meno il numero dei parametri stimati), mentre nell'ultima riga abbiamo la devianza della regressione (a sinistra) e la devianza del residuo (RSS; a destra). Per comprendere meglio le statistiche aggiuntive, dobbiamo occuparci della bontà del modello, ma non prima di aver mostrato come si esegue il fitting ai minimi quadrati con R.\n\n```{r}\nmodelReg <- lm(Yield ~ Dose, data=NWheat)\nsummary(modelReg)\n```\n\n#Valutazione della bontà del modello\n\n\n## Valutazione grafica\n\nAbbiamo già valutato la validità delle assunzioni di base per i modelli lineari, in sede di ANOVA. Ora è necessario valutare se i dati osservati sono funzione della variabile esplicativa attraverso il modello dato più l'eventuale errore casuale, senza nessuna componente sistematica di mancanza d'adattamento. Questo può essere fatto, nel modo più semplice, attraverso un grafico dei valori attesi e dei valori osservati, come quello sottostante.\n\n```{r}\nplot(Yield ~ Dose, data=NWheat)\nabline(modelReg, lty=2)\n```\n\n##Errori standard dei parametri\n\nIn secondo luogo, possiamo valutare gli errori standard delle stime dei parametri, che non debbono mai essere superiori alla metà del valore del parametro stimato, cosa che in questo caso è pienamente verificata. Se così non fosse, l'intervallo di confidenza del parametro conterrebbe lo zero, il che equivarebbe a dire che, ad esempio, la pendenza 'vera' (cioè quella della popolazione) potrebbe essere nulla. In altre parole, la retta potrebbe quindi essere 'piatta', dimostrando l'inesistenza di relazione tra la X e la Y.\n\n\n#Test F per la mancanza d'adattamento\n\nIn terzo luogo, possiamo analizzare i residui della regressione, cioè gli scostamenti dei punti rispetto alla retta e, in particolare, la somma dei loro quadrati. Possiamo vedere che questo valore è pari a 86.79, cioè il valore nell'ultima riga a destra nell'output della funzione REGR.LIN; questa quantità rappresenta tutta la variabilità dei dati che la regressione non riesce a spiegare. In R, l'ANOVA per la regressione puà essere ottenuta con il seguente comando:\n\n```{r}\nanova(modelReg)\n```\n\n\nPossiamo notare che l'errore della regressione è più alto di quello dell'analisi della varianza, dato che il residuo dell'ANOVA contiene solo la misura dello scostamento di ogni dato rispetto alla media del suo gruppo, che si può considerare 'errore puro', mentre il residuo della regressione, oltre all'errore puro, contiene anche una componente detta 'mancanza d'adattamento' (lack of fit), misurabile con lo scostamento di ogni media dalla linea di regressione. In effetti, la regressione lineare è solo un'approssimazione della reale relazione biologica tra la concimazione e la produzione del frumento.\n\nLa devianza dovuta a mancanza d'adattamento puà essere quantificata per differenza:\n\n\n$$\\textrm{Lack of fit} = 86.79 - 75.46 = 11.33$$\n\nSe consideriamo i gradi di libertà, la devianza totale ne ha 15 (numero dei dati - 1), la devianza del residuo della regressione ne ha 14 (penultima riga a destra nell'output di REGR.LIN, pari al numero dei dati - il numero dei parametri stimati), l'errore sperimentale puro ne ha 12 (vedi l'ANOVA), il lack of fit ne ha quindi 14 - 12 = 2. Possiamo testare la significanza del lack of fit, utilizzando un test di F: se questo è significativo allora la componente di mancanza d'adattamento non è trascurabile, ed il modello di regressione dovrebbe essere rifiutato. In R, cioò equivale a confrontare i due modelli: ANOVA e regressione, con la funzione anova().\n\n```{r}\nanova(modelReg, model)\n```\n\nVediamo che il test di F non è significativo. Ciò supporta l'idea che non vi sia mancanza d'adattamento e quindi la regressione fornisce una descrizione adeguata dei dati sperimentali.\n\n## Test F per la bontà di adattamento e coefficiente di determinazione\n\nPossiamo considerare la varianza spiegata dalla regressione (1729.06), che può essere confrontata con l'errore puro (appunto dato dalla varianza del residuo dell'ANOVA) tramite test F:\n\n```{r}\nF <- anova(modelReg)[1,3]/anova(model)[2,3]\ndf(F, 1, 12)\n```\n\nPiù frequentemente, la devianza spiegata dalla regressione viene rapportata alla devianza totale, per individuare quanta parte della variabilità dei dati è spiegata dal modello prescelto. Questa proporzione definisce il cosidetto **coefficente di determinazione** o $R^2$ (terza riga a sinistra nell'output di REGR.LIN):\n\n\n$$R^2 = \\frac{SS_{reg}}{SS_{tot}} = \\frac{1729.06}{1815.85} = 0.952$$\n \nQuesta statistica varia da 0 ad 1 e la regressione è tanto migliore quanto più essa si avvicina ad 1.\n\n\n#Conclusione\n\n1. Considerando i risultati finora esposti possiamo concludere che la produzione del frumento è legata alla dose di concimazione (tra 0 e 180 kg/ha) da una relazione lineare significativa.\n2. Per ogni 10 kg/ha di incremento di N, la pianta risponde con un incremento produttivo del 15.5\\%\n3. il modello adattato ai dati può essere utilizzato per ottenere le produzioni a dosi intermedie, che non sono state incluse in prova, purché ci si mantenga entro il valore massimo e quello minimo saggiati. In R, ciò è possibile utilizzando la funzione predict().\n\n```{r}\npredict(modelReg, newdata=data.frame(Dose=80), se=T)\n```\n\n\n\n```{r results='hide', echo=F}\n#Simulate a regression\nb0 <- c()\nb1 <- c()\nfor(i in 1:10000){\n  d <- unlist(simulate(modelReg, nsim=1))\n  reg <- lm(d ~ NWheat$Dose)\n  b0 <- c(b0, coef(reg)[1])\n  b1 <- c(b1, coef(reg)[2])\n}\nmean(b0); sd(b0)\nmean(b1); sd(b1)\nsummary(modelReg)\n```\n\n",
    "created" : 1528714959805.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3762678610",
    "id" : "3A1E4A13",
    "lastKnownWriteTime" : 1528820216,
    "last_content_update" : 1528820216087,
    "path" : "~/Documents/_DBXAndrea/Dropbox/_Lavoro/__Notes/__Stats/40 - LinearModels/_LinearRegressionModels/_ParametrizzazioneModelliLinear/Nwheat/NWheat.Rmd",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}